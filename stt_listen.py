# audio_recorder_v2.py

import multiprocessing
import time
import os
import pyaudio
import wave
import tempfile

# PyAudio ë…¹ìŒ ì„¤ì •
CHUNK = 2048
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000  # Whisper ê¶Œì¥ ìƒ˜í”Œë ˆì´íŠ¸



# --- í—¬í¼ í•¨ìˆ˜: ì˜ìƒ ì¬ìƒ ---
def play_fullscreen_video(video_path):

    import vlc



    if not os.path.isfile(video_path):
        print(f"[ì˜¤ë¥˜] ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
        return

    # --input-repeat=-1 ì˜µì…˜ìœ¼ë¡œ ë¬´í•œ ë°˜ë³µ ì„¤ì •
    instance = vlc.Instance("--no-xlib --quiet --input-repeat=-1")
    player = instance.media_player_new()
    media = instance.media_new(video_path)
    player.set_media(media)
    player.set_fullscreen(True)
    player.play()

    # í”„ë¡œì„¸ìŠ¤ê°€ ì¢…ë£Œ ì‹ í˜¸ë¥¼ ë°›ì„ ë•Œê¹Œì§€ ëŒ€ê¸°
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        pass
    finally:
        player.stop()



# --- í—¬í¼ í•¨ìˆ˜: ì˜¤ë””ì˜¤ ë…¹ìŒ (gpt_stt.py ë¡œì§ í†µí•©) ---
def record_audio_pyaudio(duration, sample_rate):
    """
    PyAudioë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë…¹ìŒí•˜ê³  ì„ì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    p = pyaudio.PyAudio()
    stream = p.open(format=FORMAT, channels=CHANNELS, rate=sample_rate,
                    input=True, frames_per_buffer=CHUNK)

    print(f"\n[ë§ˆì´í¬] ì§€ê¸ˆë¶€í„° {duration}ì´ˆ ë™ì•ˆ ë…¹ìŒì„ ì‹œì‘í•©ë‹ˆë‹¤. ë§ì”€í•´ì£¼ì„¸ìš”...")
    frames = []
    for _ in range(0, int(sample_rate / CHUNK * duration)):
        data = stream.read(CHUNK, exception_on_overflow=False)
        frames.append(data)
    print("[ë§ˆì´í¬] ë…¹ìŒ ì™„ë£Œ.")

    stream.stop_stream()
    stream.close()
    p.terminate()

    temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    with wave.open(temp_wav.name, 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(p.get_sample_size(FORMAT))
        wf.setframerate(sample_rate)
        wf.writeframes(b''.join(frames))

    return temp_wav.name



# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---
def mic_listen(loading_video: str, ready_video: str, duration: int = 5) -> str:
    """
    ëª¨ë¸ ë¡œë”©, ë…¹ìŒ ëŒ€ê¸°, ìŒì„± ë³€í™˜ ìƒíƒœë¥¼ ë³„ë„ì˜ ì˜ìƒìœ¼ë¡œ í‘œì‹œí•˜ë©° ìŒì„± ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("--- ìŒì„± ì¸ì‹ ì‹œí€€ìŠ¤ ì‹œì‘ ---")

    # 1. 'ë¡œë”© ì¤‘' ì˜ìƒ ì¬ìƒ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    loading_process = multiprocessing.Process(target=play_fullscreen_video, args=(loading_video,), daemon=True)
    loading_process.start()
    print(f"[ì‹œìŠ¤í…œ] ë¡œë”© ì˜ìƒ ì¬ìƒ ì‹œì‘: {loading_video}")


    import whisper
    # 2. Whisper ëª¨ë¸ ë¡œë“œ (ì‹œê°„ì´ ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…)
    print("[Whisper] ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    model = whisper.load_model("large-v3")
    print("[Whisper] ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    # 3. 'ë¡œë”© ì¤‘' ì˜ìƒ ì¢…ë£Œ
    loading_process.terminate()
    loading_process.join()
    print("[ì‹œìŠ¤í…œ] ë¡œë”© ì˜ìƒ ì¢…ë£Œ.")

    # 4. 'ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ' ì˜ìƒ ì¬ìƒ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    ready_process = multiprocessing.Process(target=play_fullscreen_video, args=(ready_video,), daemon=True)
    ready_process.start()
    print(f"[ì‹œìŠ¤í…œ] ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ ì˜ìƒ ì¬ìƒ ì‹œì‘: {ready_video}")

    # 5. ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹¤í–‰
    audio_path = record_audio_pyaudio(duration=duration, sample_rate=RATE)

    # 6. 'ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ' ì˜ìƒ ì¢…ë£Œ
    ready_process.terminate()
    ready_process.join()
    print("[ì‹œìŠ¤í…œ] ë…¹ìŒ ì¤€ë¹„ ì™„ë£Œ ì˜ìƒ ì¢…ë£Œ.")

    # --- ğŸ‘‡ [ë³€ê²½] ìŒì„± ë³€í™˜ ì¤‘ 'ë¡œë”©' ì˜ìƒ ì¬ìƒ ---
    # 7. ìŒì„± ë³€í™˜ì„ ìœ„í•œ 'ë¡œë”© ì¤‘' ì˜ìƒ ì¬ìƒ í”„ë¡œì„¸ìŠ¤ ì‹œì‘
    transcribing_process = multiprocessing.Process(target=play_fullscreen_video, args=(loading_video,), daemon=True)
    transcribing_process.start()
    print(f"[ì‹œìŠ¤í…œ] ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜ìƒ ì¬ìƒ ì‹œì‘: {loading_video}")

    # 8. ë…¹ìŒëœ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    print("[Whisper] ìŒì„± ì¸ì‹ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    result = model.transcribe(audio_path, language="ko")
    transcribed_text = result["text"]
    print(f"[Whisper] ë³€í™˜ ê²°ê³¼: {transcribed_text}")

    # 9. ìŒì„± ë³€í™˜ ì™„ë£Œ í›„ 'ë¡œë”© ì¤‘' ì˜ìƒ ì¢…ë£Œ
    transcribing_process.terminate()
    transcribing_process.join()
    print("[ì‹œìŠ¤í…œ] ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜ìƒ ì¢…ë£Œ.")
    # --- ğŸ‘† [ë³€ê²½] ì—¬ê¸°ê¹Œì§€ ---

    # 10. ì„ì‹œ ë…¹ìŒ íŒŒì¼ ì‚­ì œ
    os.remove(audio_path)

    print("--- ìŒì„± ì¸ì‹ ì‹œí€€ìŠ¤ ì™„ë£Œ ---\n")
    return transcribed_text